{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baebd436-1fcb-4e0a-94c4-07bc80bebedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 15 18:05:38 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 551.68       CUDA Version: 12.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   46C    P8    16W / 220W |    571MiB /  8192MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "dataset = \"huggingartists\"\n",
    "artist_name = \"bob-dylan\"\n",
    "check_dataset = True\n",
    "num_train_epochs = 1\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967be27c-2564-4a50-85f1-af8c844cae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install accelerate peft bitsandbytes transformers trl\n",
    "#!pip install -q ipdb      # debugging.\n",
    "#!pip install -q colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0018e2ce-38de-4c85-9860-66efc02167ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 18:05:42.329756: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-15 18:05:42.387500: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 18:05:43.116720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4686e9e-b0e7-4b69-95e3-16b0f40395dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ada95c-e770-48ce-8e58-54910734f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "import datasets\n",
    "import peft\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import colorama\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6eeb86-011e-47e6-805b-692a6b4abf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "API = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841e01be-bdf5-449e-a816-ec663e2b6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74be7ffb-b6fc-45c3-abee-7f977d6c98c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=API)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1baa6c0-70c0-4063-b5c2-44309818772d",
   "metadata": {},
   "source": [
    "# ðŸ¥¶ LET's LOAD THE MODEL - ðŸ¦™ðŸ¦™ðŸ¦™ LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee668778-16a1-42f7-8d22-73709db0db45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add74e20835a44dfb256e76382d7b20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    token=API\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899b46ec-d420-4b8e-83db-f4b9000678c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c045a2e6-7cae-4197-81e7-a8cf38ce397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd58165-5fd7-4863-9071-7bbadd62162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6a6067-6617-49f5-b7ac-a5243339ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in huggingface_hub.list_datasets(author=dataset):\n",
    "  music_artist = ds.id.replace(f\"{dataset}/\", \"\")\n",
    "  #print(f\"{music_artist}\")\n",
    "  all_data[music_artist] = ds.id # searching for Bob dylan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56130e88-4fa7-4745-824b-0dca8d2bb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = all_data[artist_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1ce5729-c344-4ac2-8963-c4fce8183b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingartists/bob-dylan'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9eff2b2-7bb7-47c7-9975-662b7b500d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropdown = widgets.Dropdown(\n",
    "    options=all_data.keys(),\n",
    "    value=artist_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2176ef0d-dfff-40df-954c-3495f7663cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output() # inicio widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f17736-34c0-43ca-9081-b884b3d6ad81",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "003d3e50-0c10-49aa-95a4-28521deb267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes and functions\n",
    "def print_sample(prompt: str, sample: str):\n",
    "  print(colorama.Fore.MAGENTA + prompt, end=\"\")\n",
    "  print(colorama.Fore.BLUE + sample)\n",
    "  print(colorama.Fore.RESET)\n",
    "\n",
    "def tokenize(prompt):\n",
    "  result = tokenizer(\n",
    "      prompt,\n",
    "      truncation=True,\n",
    "      max_length=max_num_tokens,\n",
    "      padding=\"max_length\",\n",
    "  )\n",
    "  return {\n",
    "      \"input_ids\": result[\"input_ids\"],\n",
    "      \"attention_mask\": result[\"attention_mask\"],\n",
    "  }\n",
    "\n",
    "def get_num_layers(model):\n",
    "    numbers = set()\n",
    "    for name, _ in model.named_parameters():\n",
    "        for number in re.findall(r'\\d+', name):\n",
    "            numbers.add(int(number))\n",
    "    return max(numbers)\n",
    "\n",
    "def get_last_layer_linears(model):\n",
    "    names = []\n",
    "\n",
    "    num_layers = get_num_layers(model)\n",
    "    for name, module in model.named_modules():\n",
    "        if str(num_layers) in name and not \"encoder\" in name:\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                names.append(name)\n",
    "    return names\n",
    "\n",
    "def tokenize(prompt):\n",
    "  result = tokenizer(\n",
    "      prompt,\n",
    "      truncation=True,\n",
    "      max_length=256,\n",
    "      padding=\"max_length\",\n",
    "  )\n",
    "  return {\n",
    "      \"input_ids\": result[\"input_ids\"],\n",
    "      \"attention_mask\": result[\"attention_mask\"],\n",
    "  }\n",
    "\n",
    "def on_change(change):\n",
    "  global dataset_name\n",
    "  global artist_name\n",
    "  artist_name = change['new']\n",
    "  dataset_name = all_data[artist_name]\n",
    "  print(f\"New artist: {artist_name}\")\n",
    "\n",
    "def run_sample(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt: str,\n",
    "    seed: int | None = None,\n",
    "    temperature: float = 0.6,\n",
    "    top_p: float = 0.9,\n",
    "    max_new_tokens: int = 20,\n",
    ") -> str:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs_id = inputs['input_ids'].to(model.device)\n",
    "    attention_mask = inputs['attention_mask'].to(model.device)\n",
    "\n",
    "    # set generation config\n",
    "    generation_config = transformers.GenerationConfig(\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        top_k=0\n",
    "    )\n",
    "\n",
    "    if seed is not None:\n",
    "      torch.manual_seed(seed)\n",
    "\n",
    "    generation_output = model.generate(\n",
    "        input_ids=inputs_id,\n",
    "        attention_mask=attention_mask,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    assert len(generation_output.sequences) == 1\n",
    "    output_sequence = generation_output.sequences[0]\n",
    "    output_string = tokenizer.decode(output_sequence)\n",
    "    response = output_string.split(prompt)[-1].rstrip()\n",
    "    print(prompt, response)\n",
    "    return response\n",
    "\n",
    "class PlotLossCalback(transformers.TrainerCallback):\n",
    "  def on_epoch_end(self, args, state, control, model=None, tokenizer=None, logs=None, **kwargs):\n",
    "    states_history = state.log_history\n",
    "    losses, learning_rates, steps = [], [], []\n",
    "    for curr_state in state.log_history:\n",
    "      if 'loss' not in curr_state:\n",
    "        continue\n",
    "      losses.append(curr_state['loss'])\n",
    "      learning_rates.append(curr_state['learning_rate'])\n",
    "      steps.append(curr_state['step'])\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax1.plot(steps, losses, '-ob')\n",
    "    ax1.set_title('Step vs Loss')\n",
    "    ax2.plot(steps, learning_rates, '-or')\n",
    "    ax2.set_title('Step vs Learning Rate')\n",
    "    plt.show()\n",
    "\n",
    "class HackyTrainerThatRunsSampleInTheLoop(transformers.Trainer):\n",
    "  def prediction_step(\n",
    "      self,\n",
    "      model,\n",
    "      inputs,\n",
    "      prediction_loss_only: bool,\n",
    "      ignore_keys: list[str] | None = None,\n",
    "  ) -> tuple[torch.Tensor | None, torch.Tensor | None, torch.Tensor | None]:\n",
    "    del inputs, prediction_loss_only, ignore_keys\n",
    "    _ = run_sample(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        prompt=prompt+ QUERY_USED_DURING_TRAINING,\n",
    "        seed=1,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35ed9a23-23a6-48bf-9705-b5a45abb686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97e2f5620d04ae89c3901dc4dbc2c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(index=32, options=('100-gecs', '21-savage', '25-17', '50-cent', '5nizza', '5opka', '6ix9ine', 'aaron-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dropdown.observe(on_change, names=\"value\")\n",
    "display(Dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1a6df38-a991-4853-8210-bd4bf7caea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a song by Bob Dylan. It goes like this:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_artist_name = artist_name.replace('-', ' ').title()\n",
    "prompt = f'This is a song by {formatted_artist_name}. It goes like this:\\n\\n'\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d35a933-5fd4-4d34-b184-c7e50cfc1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.load_dataset(\n",
    "    dataset_name,\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2af532b9-4a4c-43fd-865b-2e59c578a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.filter(lambda example, idx: idx < 1000, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f17b140-4573-4c7b-be9a-545bf909210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_tokens = 20 \n",
    "\n",
    "num_chars, num_tokens = [], []\n",
    "\n",
    "for i, text in enumerate(train_dataset['text']):\n",
    "  text = prompt + text\n",
    "  num_tokens.append(len(tokenizer.tokenize(text)))\n",
    "  num_chars.append(len(text))\n",
    "\n",
    "num_chars = np.array(num_chars)\n",
    "num_tokens = np.array(num_tokens)\n",
    "num_truncations = np.sum(num_tokens > max_num_tokens)\n",
    "num_truncated_tokens = num_tokens - max_num_tokens\n",
    "median_num_truncated_tokens = np.median(\n",
    "    np.where(num_truncated_tokens > 0, num_truncated_tokens, 0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afe020ee-d945-4cbb-a5e3-31698a8c0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.filter(\n",
    "    lambda x: len(x[\"text\"]) > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68c9d8a7-cf76-4f56-b2ed-df9b786f97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mThis is a song by Bob Dylan. It goes like this:\n",
      "\n",
      "\u001b[34mTwas a dark day in Dallas, November 63\n",
      "A day that will live on in infamy\n",
      "Presidentâ€…Kennedyâ€…was a-ridin high\n",
      "Goodâ€…day to be livin and aâ€…good day to die\n",
      "Being led to the slaughter like a sacrificial lamb\n",
      "He said, Wait a minute, boys, you know who I am?\n",
      "Of course we do, we know who you are\n",
      "Then they blew off his head while he was still in the car\n",
      "Shot down like a dog in broad daylight\n",
      "Was a matter of timing and the timing was right\n",
      "You got unpaid debts, weve come to collect\n",
      "Were gonna kill you with hatred, without any respect\n",
      "Well mock you and shock you and well grin in your face\n",
      "Weve already got someone here to take your place\n",
      "The day they blew out the brains of the king\n",
      "Thousands were watching, no one saw a thing\n",
      "It happened so quickly, so quick, by surprise\n",
      "Right there in front of everyones eyes\n",
      "Greatest magic trick ever under the sun\n",
      "Perfectly executed, skillfully done\n",
      "Wolfman, oh Wolfman, oh Wolfman, howl\n",
      "Rub-a-dub-dub, its a murder most foul\n",
      "Hush, little children, youll understand\n",
      "The Beatles are comin, theyre gonna hold your hand\n",
      "Slide down the banister, go get your coat\n",
      "Ferry cross the Mersey and go for the throat\n",
      "Theres three bums comin all dressed in rags\n",
      "Pick up the pieces and lower the flags\n",
      "Im goin to Woodstock, its the Aquarian Age\n",
      "Then Ill go over to Altamont and sit near the stage\n",
      "Put your head out the window, let the good times roll\n",
      "Theres a party going on behind the Grassy Knoll\n",
      "Stack up the bricks, pour the cement\n",
      "Dont say Dallas dont love you, Mr. President\n",
      "Put your foot in the tank and then step on the gas\n",
      "Try to make it to the triple underpass\n",
      "Blackface singer, whiteface clown\n",
      "Better not show your faces after the sun goes down\n",
      "Up in the red light district, like a cop on the beat\n",
      "Living in a nightmare on Elm Street\n",
      "When youre down on Deep Ellum, put your money in your shoe\n",
      "Dont ask what your country can do for you\n",
      "Cash on the barrelhead, money to burn\n",
      "Dealey Plaza, make a left-hand turn\n",
      "Im going down to the crossroads, gonna flag a ride\n",
      "The place where faith, hope, and charity died\n",
      "Shoot him while he runs, boy, shoot him while you can\n",
      "See if you can shoot the invisible man\n",
      "Goodbye, Charlie, goodbye, Uncle Sam\n",
      "Frankly, Miss Scarlett, I dont give a damn\n",
      "What is the truth, and where did it go?\n",
      "Ask Oswald and Ruby, they oughta know\n",
      "Shut your mouth, said a wise old owl\n",
      "Business is business, and its a murder most foul\n",
      "Tommy, can you hear me? Im the Acid Queen\n",
      "Im riding in a long, black Lincoln limousine\n",
      "Ridin in the back seat next to my wife\n",
      "Headed straight on in to the afterlife\n",
      "Im leaning to the left, I got my head in her lap\n",
      "Oh Lord, Ive been led into some kind of a trap\n",
      "Where we ask no quarter, and no quarter do we give\n",
      "Were right down the street, from the street where you live\n",
      "They mutilated his body and they took out his brain\n",
      "What more could they do? They piled on the pain\n",
      "But his soul was not there where it was supposed to be at\n",
      "For the last fifty years theyve been searchin for that\n",
      "Freedom, oh freedom, freedom over me\n",
      "I hate to tell you, mister, but only dead men are free\n",
      "Send me some lovin, then tell me no lie\n",
      "Throw the gun in the gutter and walk on by\n",
      "Wake up, little Susie, lets go for a drive\n",
      "Cross the Trinity River, lets keep hope alive\n",
      "Turn the radio on, dont touch the dials\n",
      "Parkland Hospital, only six more miles\n",
      "You got me dizzy, Miss Lizzy, you filled me with lead\n",
      "That magic bullet of yours has gone to my head\n",
      "Im just a patsy like Patsy Cline\n",
      "Never shot anyone from in front or behind\n",
      "Ive blood in my eye, got blood in my ear\n",
      "Im never gonna make it to the new frontier\n",
      "Zapruders film, Ive seen that before\n",
      "Seen it thirty-three times, maybe more\n",
      "Its vile and deceitful, its cruel and its mean\n",
      "Ugliest thing that you ever have seen\n",
      "They killed him once and they killed him twice\n",
      "Killed him like a human sacrifice\n",
      "The day that they killed him, someone said to me, Son\n",
      "The age of the Antichrist has just only begun\n",
      "Air Force One comin in through the gate\n",
      "Johnson sworn in at 2:38\n",
      "Let me know when you decide to throw in the towel\n",
      "It is what it is, and its murder most foul\n",
      "Whats new, pussycat? Whatd I say?\n",
      "I said the soul of a nation been torn away\n",
      "And its beginning to go into a slow decay\n",
      "And that its thirty-six hours past Judgment Day\n",
      "Wolfman Jack, hes speaking in tongues\n",
      "Hes going on and on at the top of his lungs\n",
      "Play me a song, Mr. Wolfman Jack\n",
      "Play it for me in my long Cadillac\n",
      "Play me that Only the Good Die Young\n",
      "Take me to the place Tom Dooley was hung\n",
      "Play St. James Infirmary in the Court of King James\n",
      "If you want to remember, you better write down the names\n",
      "Play Etta James, too, play Id Rather Go Blind\n",
      "Play it for the man with the telepathic mind\n",
      "Play John Lee Hooker, play Scratch My Back\n",
      "Play it for that strip club owner named Jack\n",
      "Guitar Slim going down slow\n",
      "Play it for me and for Marilyn Monroe\n",
      "Play Please Dont Let Me Be Misunderstood\n",
      "Play it for the First Lady, she aint feeling any good\n",
      "Play Don Henley, play Glenn Frey\n",
      "Take it to the limit and let it go by\n",
      "Play it for Carl Wilson, too\n",
      "Looking far, far away down Gower Avenue\n",
      "Play Tragedy, play Twilight Time\n",
      "Take me back to Tulsa to the scene of the crime\n",
      "Play another one and Another One Bites the Dust\n",
      "Play The Old Rugged Cross and In God We Trust\n",
      "Ride the pink horse down that long, lonesome road\n",
      "Stand there and wait for his head to explode\n",
      "Play Mystery Train for Mr. Mystery\n",
      "The man who fell down dead like a rootless tree\n",
      "Play it for the reverend, play it for the pastor\n",
      "Play it for the dog that got no master\n",
      "Play Oscar Peterson, play Stan Getz\n",
      "Play Blue Sky, play Dickey Betts\n",
      "Play Art Pepper, Thelonious Monk\n",
      "Charlie Parker and all that junk\n",
      "All that junk and All That Jazz\n",
      "Play something for the Birdman of Alcatraz\n",
      "Play Buster Keaton, play Harold Lloyd\n",
      "Play Bugsy Siegel, play Pretty Boy Floyd\n",
      "Play the numbers, play the odds\n",
      "Play Cry Me a River for the Lord of the gods\n",
      "Play Number nine, play Number six\n",
      "Play it for Lindsey and Stevie Nicks\n",
      "Play Nat King Cole, play Nature Boy\n",
      "Play Down in the Boondocks for Terry Malloy\n",
      "Play It Happened One Night and One Night of Sin\n",
      "Theres twelve million souls that are listening in\n",
      "Play Merchant of Venice, play Merchants of Death\n",
      "Play Stella by Starlight for Lady Macbeth\n",
      "Dont worry, Mr. President, helps on the way\n",
      "Your brothers are comin, therell be hell to pay\n",
      "Brothers? What brothers? Whats this about hell?\n",
      "Tell them, Were waiting, keep coming, well get them as well\n",
      "Love Field is where his plane touched down\n",
      "But it never did get back up off the ground\n",
      "Was a hard act to follow, second to none\n",
      "They killed him on the altar of the rising sun\n",
      "Play Misty for me and That Old Devil Moon\n",
      "Play Anything Goes and Memphis in June\n",
      "Play Lonely at the Top and Lonely Are the Brave\n",
      "Play it for Houdini spinning around in his grave\n",
      "Play Jelly Roll Morton, play Lucille\n",
      "Play Deep in a Dream, and play Driving Wheel\n",
      "Play Moonlight Sonata in F-sharp\n",
      "And A Key to the Highway for the king on the harp\n",
      "Play Marching Through Georgia and Dumbartons Drums\n",
      "Play Darkness and death will come when it comes\n",
      "Play Love Me or Leave Me by the great Bud Powell\n",
      "Play The Blood-Stained Banner, play Murder Most Foul\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "print_sample(prompt, train_dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea76f60f-8605-4ded-82b6-e6d1c8ac2426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 991\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c4b442-9ac2-4867-a04a-14251fb5f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda x: {\n",
    "        \"text\":prompt + x[\"text\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9ed6b94-d67d-4886-a28b-b4ed1fe12729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3b6ee76a844797968ef9704c9260f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/991 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.shuffle().map(lambda x: tokenize(x[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be9d867a-a68e-4ffb-b13c-7cad15448c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Hyper-parameters\n",
    "MICRO_BATCH_SIZE = 4 # @param\n",
    "BATCH_SIZE = 32 # @param\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "EPOCHS = 40 # @param\n",
    "LEARNING_RATE = 3e-4 # @param\n",
    "CUTOFF_LEN = max_num_tokens\n",
    "LORA_R = 12 # @param\n",
    "LORA_ALPHA = 12 # @param\n",
    "LORA_DROPOUT = 0.2 # @param\n",
    "WARMUP_STEPS = 20 # @param\n",
    "QUERY_USED_DURING_TRAINING = \"Dreams of llamas\" # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec307da1-fec8-4b29-8c5f-b9c528ea1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ac0c223-0c0f-4c55-9283-033d70e88fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = peft.LoraConfig(\n",
    "    task_type=peft.TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    # Default is to apply lora to Q and V projection matrices.\n",
    "    # These are based on results of Table 5 of the paper.\n",
    "    target_modules=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4992c586-3760-4877-aa0e-19a9b8584fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,111,808 || all params: 8,035,373,056 || trainable%: 0.0636\n"
     ]
    }
   ],
   "source": [
    "peft_model = peft.get_peft_model(copy.deepcopy(model), peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accfde43-46bd-42d3-be30-7df399d9d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariochiaparini/miniconda3/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_arguments = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=MICRO_BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=True,\n",
    "    logging_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_steps=10,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    output_dir=\"tmp\",\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9d22c43-005b-49ec-acac-b134326bd4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 18:10:16] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 18:10:16] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 18:10:16] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 18:10:16] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 18:10:16] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 18:10:18] We saw that you have a 13th Gen Intel(R) Core(TM) i7-13700K but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 18:10:18] CPU Model on constant consumption mode: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "[codecarbon INFO @ 18:10:18] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 18:10:18]   Platform system: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 18:10:18]   Python version: 3.10.13\n",
      "[codecarbon INFO @ 18:10:18]   CodeCarbon version: 2.3.5\n",
      "[codecarbon INFO @ 18:10:18]   Available RAM : 15.482 GB\n",
      "[codecarbon INFO @ 18:10:18]   CPU count: 24\n",
      "[codecarbon INFO @ 18:10:18]   CPU model: 13th Gen Intel(R) Core(TM) i7-13700K\n",
      "[codecarbon INFO @ 18:10:18]   GPU count: 1\n",
      "[codecarbon INFO @ 18:10:18]   GPU model: 1 x NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "trainer = HackyTrainerThatRunsSampleInTheLoop(\n",
    "    model=peft_model,\n",
    "    train_dataset=train_dataset,\n",
    "    # Unused. But needed to run hacky inference.\n",
    "    eval_dataset=[{'input_ids': [], 'attention_mask': []}],\n",
    "    args=training_arguments,\n",
    "    callbacks=[PlotLossCalback],\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aef672b-d574-49e4-813d-2d9244e8990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb49aa-2c74-4ffe-8049-16a3d02a3179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db8472-cfe5-4a56-a823-ce87f372ad79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd799c-8134-4de4-8ada-d35148dd0906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6183d1-5f30-4691-92ba-01ef45bff1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50409093-f8dd-4bb0-9d90-bd48e89a7403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2cfa46-5cc7-4c1f-bd1e-733ea0b7696a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc670f1-e0c1-42cc-b6c9-940859836fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be96752-ddf1-4a80-a20b-ff8d6e74f96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86a377-b0c7-4084-8501-8be5b5afd407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cef6af-fcb8-4e27-9c3c-87182e2e25f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4b986-1712-4d39-ad04-ec40b18a9126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807bf26-f404-4e56-84d7-9d02c582e6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993028e0-86a9-43ea-9cb2-2ecf200a5e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744521f3-c7a7-48a8-b3c4-90e33b28937e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09a9a8-779a-471d-a464-052a2db87eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
